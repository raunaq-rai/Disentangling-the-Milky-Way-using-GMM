{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e31fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "from tqdm import tqdm\n",
    "import astropy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import galpy\n",
    "from galpy.orbit import Orbit\n",
    "from galpy.potential import MWPotential2014\n",
    "from astropy.coordinates import SkyCoord, Galactocentric, CartesianDifferential, ICRS, Galactic, CylindricalRepresentation, CylindricalDifferential\n",
    "from matplotlib.colors import Normalize\n",
    "from galpy.util.coords import lbd_to_XYZ, XYZ_to_galcencyl\n",
    "import warnings\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae2cf0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading HDF5 columns: 100%|██████████| 30/30 [00:00<00:00, 57.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df_vis with shape (14485519, 30)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('../data/JDrgb_14m_hasrv.hdf5', 'r') as f:\n",
    "    columns_group = f['table/columns']\n",
    "    col_names = list(columns_group.keys())\n",
    "    data_dict = {}\n",
    "\n",
    "    for col in tqdm(col_names, desc=\"Reading HDF5 columns\"):\n",
    "        dataset = columns_group[col]\n",
    "        subkey = list(dataset.keys())[0]\n",
    "        data = dataset[subkey][:]\n",
    "        if data.dtype.kind == 'S':\n",
    "            data = data.astype(str)\n",
    "        data_dict[col] = data\n",
    "\n",
    "df_vis = pd.DataFrame(data_dict)\n",
    "print(f\"Loaded df_vis with shape {df_vis.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5290d33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FITS...\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading FITS...\")\n",
    "with fits.open('../data/table_2_catwise.fits.gz', memmap=True) as hdul:\n",
    "    data = hdul[1].data\n",
    "    df_RGB = pd.DataFrame({\n",
    "        col.name: data[col.name].byteswap().newbyteorder() if data[col.name].dtype.byteorder == '>' else data[col.name]\n",
    "        for col in hdul[1].columns\n",
    "    })\n",
    "\n",
    "df_rgb_subset = df_RGB[['source_id', 'catwise_w1', 'catwise_w2', 'mh_xgboost', 'teff_xgboost', 'logg_xgboost']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a00434c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging dataframes...\n",
      "Merged shape: (14485519, 35)\n"
     ]
    }
   ],
   "source": [
    "print(\"Merging dataframes...\")\n",
    "df_vis['source_id'] = df_vis['source_id'].astype(str)\n",
    "df_rgb_subset = df_RGB[['source_id', 'catwise_w1', 'catwise_w2', 'mh_xgboost', 'teff_xgboost', 'logg_xgboost']].copy()\n",
    "df_rgb_subset['source_id'] = df_rgb_subset['source_id'].astype(str)\n",
    "df_merged = pd.merge(df_vis, df_rgb_subset, on='source_id', how='left')\n",
    "print(f\"Merged shape: {df_merged.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6692a5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Number of rows in df_vis without a match from df_rgb_subset: 2507010\n"
     ]
    }
   ],
   "source": [
    "# Count how many rows have any missing values in the columns added from df_rgb_subset\n",
    "num_missing = df_merged[['catwise_w1', 'catwise_w2', 'mh_xgboost', 'teff_xgboost', 'logg_xgboost']].isna().any(axis=1).sum()\n",
    "\n",
    "print(f\"[✓] Number of rows in df_vis without a match from df_rgb_subset: {num_missing}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ab35306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Shape after dropping unmatched rows: (11978509, 35)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing values in any of the merged columns\n",
    "df_merged = df_merged.dropna(subset=['catwise_w1', 'catwise_w2', 'mh_xgboost', 'teff_xgboost', 'logg_xgboost'])\n",
    "\n",
    "print(f\"[✓] Shape after dropping unmatched rows: {df_merged.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "128fc90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying quality cuts...\n",
      "After cuts: (10456910, 41)\n"
     ]
    }
   ],
   "source": [
    "print(\"Applying quality cuts...\")\n",
    "\n",
    "df_merged['parallax_over_error'] = df_merged['parallax'] / df_merged['parallax_error']\n",
    "\n",
    "df_merged['MW1'] = df_merged['catwise_w1'] + 5 * np.log10(df_merged['parallax'] / 100)\n",
    "\n",
    "df_merged['G'] = df_merged['phot_g_mean_mag']\n",
    "\n",
    "df_merged['GBP'] = df_merged['phot_bp_mean_mag']\n",
    "\n",
    "df_merged['W1'] = df_merged['catwise_w1']\n",
    "df_merged['W2'] = df_merged['catwise_w2']\n",
    "\n",
    "cut = (\n",
    "    (df_merged['phot_g_mean_mag'] < 16) &\n",
    "    (df_merged['parallax_over_error'] > 5) &\n",
    "    (df_merged['teff_xgboost'] <= 5200) &\n",
    "    (df_merged['logg_xgboost'] < 3.5) &\n",
    "    (df_merged['MW1'] > (-0.3 - 0.006 * (5500 - df_merged['teff_xgboost']))) &\n",
    "    (df_merged['MW1'] > (-0.01 * (5300 - df_merged['teff_xgboost']))) &\n",
    "    ((df_merged['G'] - df_merged['W2']) < (0.2 + 0.77 * (df_merged['GBP'] - df_merged['W1'])))\n",
    ")\n",
    "\n",
    "df_cleaned = df_merged[cut].copy()\n",
    "print(f\"After cuts: {df_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da60d66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing nearest matches...\n",
      "After sky filtering: (10060704, 41)\n"
     ]
    }
   ],
   "source": [
    "dwarf_galaxies = Table.read(\"../local_volume_database/data/dwarf_mw.csv\")\n",
    "globular_clusters = Table.read(\"../local_volume_database/data/gc_harris.csv\")\n",
    "\n",
    "dwarf_coords = SkyCoord(ra=dwarf_galaxies['ra'] * u.deg, dec=dwarf_galaxies['dec'] * u.deg)\n",
    "gc_coords = SkyCoord(ra=globular_clusters['ra'] * u.deg, dec=globular_clusters['dec'] * u.deg)\n",
    "known_coords = SkyCoord(\n",
    "    ra=np.concatenate([dwarf_coords.ra.deg, gc_coords.ra.deg]) * u.deg,\n",
    "    dec=np.concatenate([dwarf_coords.dec.deg, gc_coords.dec.deg]) * u.deg\n",
    ")\n",
    "\n",
    "print(\"Computing nearest matches...\")\n",
    "df_cleaned['ra'] = pd.to_numeric(df_cleaned['ra'], errors='coerce')\n",
    "df_cleaned['dec'] = pd.to_numeric(df_cleaned['dec'], errors='coerce')\n",
    "df_cleaned = df_cleaned.dropna(subset=['ra', 'dec'])\n",
    "\n",
    "sample_coords = SkyCoord(ra=df_cleaned['ra'].values * u.deg, dec=df_cleaned['dec'].values * u.deg)\n",
    "\n",
    "# Use efficient nearest neighbor match instead of all-pair separation\n",
    "idx, sep2d, _ = sample_coords.match_to_catalog_sky(known_coords)\n",
    "\n",
    "# Filter stars >1 degree away\n",
    "df_final = df_cleaned[sep2d.deg > 1].copy()\n",
    "print(f\"After sky filtering: {df_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295ebc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] FITS file saved as '../data/vis_cleaned.fits'\n"
     ]
    }
   ],
   "source": [
    "from astropy.table import Table\n",
    "\n",
    "df_final['source_id'] = df_final['source_id'].astype(str)\n",
    "\n",
    "# Convert to Astropy Table\n",
    "table = Table.from_pandas(df_final)\n",
    "\n",
    "# Save to FITS\n",
    "output_fits_filename = '../data/vis_cleaned.fits'\n",
    "table.write(output_fits_filename, format='fits', overwrite=True)\n",
    "\n",
    "print(f\"[✓] FITS file saved as '{output_fits_filename}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a58a75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = Table.read(\"../data/vis_cleaned.fits\", format='fits')\n",
    "\n",
    "# Convert to a pandas DataFrame\n",
    "df_vis = table.to_pandas()\n",
    "df_vis['source_id'] = df_vis['source_id'].str.decode('utf-8').astype(np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea26f179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10060704, 41)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15206df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in gedr3dist.dump.gz:\n",
      "['source_id,r_med_geo,r_lo_geo,r_hi_geo,r_med_photogeo,r_lo_photogeo,r_hi_photogeo,flag']\n"
     ]
    }
   ],
   "source": [
    "sample = pd.read_csv(\"../data/gedr3dist.dump.gz\", sep=\"\\t\", nrows=5)\n",
    "print(\"Columns in gedr3dist.dump.gz:\")\n",
    "print(sample.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1926ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Loaded vis_cleaned: 10,060,704 rows\n",
      "Processing gedr3dist.dump.gz with source_id matching...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching chunks: 100%|██████████| 1468/1468 [1:12:25<00:00,  2.96s/chunk]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Total matched rows: 10,060,704\n",
      "[✓] Final merged DataFrame shape: (10060704, 48)\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "fits_path = \"../data/vis_cleaned.fits\"\n",
    "dump_path = \"../data/gedr3dist.dump.gz\"\n",
    "output_path = \"../data/vis_with_distances.fits\"\n",
    "\n",
    "# Load vis_cleaned and prepare source_id set\n",
    "df_vis = Table.read(fits_path, format='fits').to_pandas()\n",
    "df_vis['source_id'] = df_vis['source_id'].astype(str)\n",
    "source_set = set(df_vis['source_id'])\n",
    "print(f\"[✓] Loaded vis_cleaned: {len(df_vis):,} rows\")\n",
    "\n",
    "# Column names and types in the dump\n",
    "columns = ['source_id', 'r_med_geo', 'r_lo_geo', 'r_hi_geo',\n",
    "           'r_med_photogeo', 'r_lo_photogeo', 'r_hi_photogeo', 'flag']\n",
    "dtype_dict = {\n",
    "    \"source_id\": str,\n",
    "    \"r_med_geo\": float,\n",
    "    \"r_lo_geo\": float,\n",
    "    \"r_hi_geo\": float,\n",
    "    \"r_med_photogeo\": float,\n",
    "    \"r_lo_photogeo\": float,\n",
    "    \"r_hi_photogeo\": float,\n",
    "    \"flag\": str\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "total_rows = 1_467_744_819  # known from gzcat | wc -l\n",
    "chunk_size = 1_000_000\n",
    "n_chunks = (total_rows - 1 + chunk_size - 1) // chunk_size  # -1 to exclude header\n",
    "\n",
    "# Stream and match\n",
    "print(\"Processing gedr3dist.dump.gz with source_id matching...\")\n",
    "matches = []\n",
    "reader = pd.read_csv(\n",
    "    dump_path, \n",
    "    sep=\",\", \n",
    "    names=columns, \n",
    "    dtype=dtype_dict, \n",
    "    skiprows=1, \n",
    "    chunksize=chunk_size\n",
    ")\n",
    "\n",
    "for chunk in tqdm(reader, total=n_chunks, desc=\"Matching chunks\", unit=\"chunk\"):\n",
    "    matched = chunk[chunk['source_id'].isin(source_set)]\n",
    "    matches.append(matched)\n",
    "\n",
    "# Concatenate and merge\n",
    "df_matched = pd.concat(matches, ignore_index=True)\n",
    "print(f\"[✓] Total matched rows: {len(df_matched):,}\")\n",
    "\n",
    "df_merged = pd.merge(df_vis, df_matched, on=\"source_id\", how=\"left\")\n",
    "print(f\"[✓] Final merged DataFrame shape: {df_merged.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45ad1998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Rows after dropping NaNs in r_med_photogeo: 10,060,164\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where r_med_photogeo is NaN\n",
    "df_filtered = df_merged.dropna(subset=['r_med_photogeo'])\n",
    "\n",
    "print(f\"[✓] Rows after dropping NaNs in r_med_photogeo: {len(df_filtered):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d738483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Saved merged file to: ../data/vis_with_distances.fits\n"
     ]
    }
   ],
   "source": [
    "# Save as FITS\n",
    "table_out = Table.from_pandas(df_filtered)\n",
    "table_out.write(output_path, format='fits', overwrite=True)\n",
    "print(f\"[✓] Saved merged file to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0121a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aom_xp</th>\n",
       "      <th>b</th>\n",
       "      <th>bp_rp</th>\n",
       "      <th>dec</th>\n",
       "      <th>e_aom_xp</th>\n",
       "      <th>e_logg_xp</th>\n",
       "      <th>e_moh_xp</th>\n",
       "      <th>e_teff_xp</th>\n",
       "      <th>fake_MG</th>\n",
       "      <th>l</th>\n",
       "      <th>...</th>\n",
       "      <th>GBP</th>\n",
       "      <th>W1</th>\n",
       "      <th>W2</th>\n",
       "      <th>r_med_geo</th>\n",
       "      <th>r_lo_geo</th>\n",
       "      <th>r_hi_geo</th>\n",
       "      <th>r_med_photogeo</th>\n",
       "      <th>r_lo_photogeo</th>\n",
       "      <th>r_hi_photogeo</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0189</td>\n",
       "      <td>-48.572035</td>\n",
       "      <td>1.154534</td>\n",
       "      <td>0.335043</td>\n",
       "      <td>0.0222</td>\n",
       "      <td>0.1309</td>\n",
       "      <td>0.0717</td>\n",
       "      <td>53.5303</td>\n",
       "      <td>158.232347</td>\n",
       "      <td>176.739184</td>\n",
       "      <td>...</td>\n",
       "      <td>10.750277</td>\n",
       "      <td>8.152</td>\n",
       "      <td>8.198</td>\n",
       "      <td>695.683899</td>\n",
       "      <td>683.627625</td>\n",
       "      <td>707.396423</td>\n",
       "      <td>696.278320</td>\n",
       "      <td>688.270874</td>\n",
       "      <td>707.143982</td>\n",
       "      <td>b'10033'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1512</td>\n",
       "      <td>-48.171322</td>\n",
       "      <td>1.409290</td>\n",
       "      <td>0.736093</td>\n",
       "      <td>0.0502</td>\n",
       "      <td>0.1197</td>\n",
       "      <td>0.0759</td>\n",
       "      <td>44.4781</td>\n",
       "      <td>63.236201</td>\n",
       "      <td>176.483565</td>\n",
       "      <td>...</td>\n",
       "      <td>11.150994</td>\n",
       "      <td>7.891</td>\n",
       "      <td>7.964</td>\n",
       "      <td>1884.275020</td>\n",
       "      <td>1821.247560</td>\n",
       "      <td>1947.302730</td>\n",
       "      <td>1883.143550</td>\n",
       "      <td>1807.318600</td>\n",
       "      <td>1944.665770</td>\n",
       "      <td>b'10033'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0036</td>\n",
       "      <td>-48.607026</td>\n",
       "      <td>1.189063</td>\n",
       "      <td>0.561503</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>30.6331</td>\n",
       "      <td>293.932164</td>\n",
       "      <td>176.209301</td>\n",
       "      <td>...</td>\n",
       "      <td>11.169669</td>\n",
       "      <td>8.496</td>\n",
       "      <td>8.558</td>\n",
       "      <td>452.636078</td>\n",
       "      <td>448.701294</td>\n",
       "      <td>456.615540</td>\n",
       "      <td>452.602692</td>\n",
       "      <td>449.257355</td>\n",
       "      <td>455.432892</td>\n",
       "      <td>b'10033'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2962</td>\n",
       "      <td>-48.727781</td>\n",
       "      <td>1.131072</td>\n",
       "      <td>0.689953</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>59.5872</td>\n",
       "      <td>356.979240</td>\n",
       "      <td>175.755174</td>\n",
       "      <td>...</td>\n",
       "      <td>14.816144</td>\n",
       "      <td>12.220</td>\n",
       "      <td>12.275</td>\n",
       "      <td>1908.478270</td>\n",
       "      <td>1815.024170</td>\n",
       "      <td>2014.483890</td>\n",
       "      <td>1868.603880</td>\n",
       "      <td>1800.940800</td>\n",
       "      <td>1949.831300</td>\n",
       "      <td>b'10033'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0726</td>\n",
       "      <td>-48.328584</td>\n",
       "      <td>1.328486</td>\n",
       "      <td>0.955080</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0429</td>\n",
       "      <td>27.8866</td>\n",
       "      <td>143.555092</td>\n",
       "      <td>175.789759</td>\n",
       "      <td>...</td>\n",
       "      <td>11.810220</td>\n",
       "      <td>8.728</td>\n",
       "      <td>8.815</td>\n",
       "      <td>1178.407470</td>\n",
       "      <td>1155.319820</td>\n",
       "      <td>1203.711180</td>\n",
       "      <td>1177.687260</td>\n",
       "      <td>1154.219600</td>\n",
       "      <td>1201.322750</td>\n",
       "      <td>b'10033'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aom_xp          b     bp_rp       dec  e_aom_xp  e_logg_xp  e_moh_xp  \\\n",
       "0  0.0189 -48.572035  1.154534  0.335043    0.0222     0.1309    0.0717   \n",
       "1  0.1512 -48.171322  1.409290  0.736093    0.0502     0.1197    0.0759   \n",
       "2  0.0036 -48.607026  1.189063  0.561503    0.0080     0.0742    0.0333   \n",
       "3  0.2962 -48.727781  1.131072  0.689953    0.0328     0.1724    0.0808   \n",
       "4  0.0726 -48.328584  1.328486  0.955080    0.0245     0.0762    0.0429   \n",
       "\n",
       "   e_teff_xp     fake_MG           l  ...        GBP      W1      W2  \\\n",
       "0    53.5303  158.232347  176.739184  ...  10.750277   8.152   8.198   \n",
       "1    44.4781   63.236201  176.483565  ...  11.150994   7.891   7.964   \n",
       "2    30.6331  293.932164  176.209301  ...  11.169669   8.496   8.558   \n",
       "3    59.5872  356.979240  175.755174  ...  14.816144  12.220  12.275   \n",
       "4    27.8866  143.555092  175.789759  ...  11.810220   8.728   8.815   \n",
       "\n",
       "     r_med_geo     r_lo_geo     r_hi_geo  r_med_photogeo  r_lo_photogeo  \\\n",
       "0   695.683899   683.627625   707.396423      696.278320     688.270874   \n",
       "1  1884.275020  1821.247560  1947.302730     1883.143550    1807.318600   \n",
       "2   452.636078   448.701294   456.615540      452.602692     449.257355   \n",
       "3  1908.478270  1815.024170  2014.483890     1868.603880    1800.940800   \n",
       "4  1178.407470  1155.319820  1203.711180     1177.687260    1154.219600   \n",
       "\n",
       "   r_hi_photogeo      flag  \n",
       "0     707.143982  b'10033'  \n",
       "1    1944.665770  b'10033'  \n",
       "2     455.432892  b'10033'  \n",
       "3    1949.831300  b'10033'  \n",
       "4    1201.322750  b'10033'  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = Table.read(\"../data/vis_with_distances.fits\", format='fits')\n",
    "\n",
    "# Convert to a pandas DataFrame\n",
    "df_vis = table.to_pandas()\n",
    "\n",
    "df_vis.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007e15f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10060164, 50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_galactocentric_manual(df):\n",
    "    \"\"\"\n",
    "    Manually calculate Galactocentric coordinates (R and Z).\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with necessary astrometric data.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with added Galactocentric radius (R) and Z coordinates.\n",
    "    \"\"\"\n",
    "    # Define constants\n",
    "    R_sun = 8.122  # Distance of the Sun from the Galactic centre in kpc\n",
    "\n",
    "    # Convert l and b from degrees to radians\n",
    "    l_rad = np.radians(df['l'].values)\n",
    "    b_rad = np.radians(df['b'].values)\n",
    "\n",
    "    # Use rpgeo as distance in kpc\n",
    "    d_kpc = df['r_med_photogeo'].values / 1000  # Convert from pc to kpc\n",
    "\n",
    "    # Calculate Cartesian coordinates\n",
    "    x = d_kpc * np.cos(b_rad) * np.cos(l_rad)\n",
    "    y = d_kpc * np.cos(b_rad) * np.sin(l_rad)\n",
    "    z = d_kpc * np.sin(b_rad)\n",
    "\n",
    "    # Adjust for Sun's position relative to the Galactic centre\n",
    "    x_galactocentric = x - R_sun\n",
    "\n",
    "    # Calculate cylindrical radius R\n",
    "    R = np.sqrt(x_galactocentric**2 + y**2)\n",
    "\n",
    "    # Add results to the DataFrame\n",
    "    df['R'] = R  # Galactocentric radius in kpc\n",
    "    df['Z'] = z  # Height above the Galactic plane in kpc\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the function to your DataFrame\n",
    "df = calculate_galactocentric_manual(df_vis)\n",
    "\n",
    "# Remove rows with NaN values in R or Z columns\n",
    "df = df.dropna(subset=['R', 'Z'])\n",
    "\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dae75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant columns\n",
    "l = df['l'].values  # Galactic longitude in degrees\n",
    "b = df['b'].values  # Galactic latitude in degrees\n",
    "rpgeo = df['r_med_photogeo'].values  # Distance in parsecs\n",
    "\n",
    "# Convert Galactic coordinates to Cartesian using galpy\n",
    "xyz = lbd_to_XYZ(l, b, rpgeo, degree=True)\n",
    "x, y, z = xyz.T  # Unpacking the array\n",
    "\n",
    "# Transform to Galactocentric cylindrical coordinates\n",
    "Xsun = 8.2  # Distance of the Sun from the Galactic Centre in kpc\n",
    "Zsun = 0.025  # Sun's height above the midplane in kpc\n",
    "R_phi_z = XYZ_to_galcencyl(x, y, z, Xsun=Xsun, Zsun=Zsun, _extra_rot=True)\n",
    "R, phi, z_gal = R_phi_z.T  # Unpacking the results\n",
    "\n",
    "# Add Galactocentric cylindrical coordinates to the DataFrame\n",
    "df[\"R_gal\"] = R\n",
    "df[\"phi_gal\"] = phi\n",
    "df[\"Z_gal\"] = z_gal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811de10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Sun's velocity with respect to the Galactic center\n",
    "v_sun = CartesianDifferential([11.1, 245., 7.25] * u.km / u.s)\n",
    "\n",
    "# Define the Galactocentric frame\n",
    "gc_frame = Galactocentric(galcen_distance=8.1 * u.kpc, \n",
    "                          z_sun=25 * u.pc, \n",
    "                          galcen_v_sun=v_sun)\n",
    "\n",
    "# Extract the columns as numpy arrays\n",
    "ra = df['ra'].values * u.deg\n",
    "dec = df['dec'].values * u.deg\n",
    "distance = df['r_med_photogeo'].values * u.pc  \n",
    "pmra = df['pmra'].values * u.mas / u.yr\n",
    "pmdec = df['pmdec'].values * u.mas / u.yr\n",
    "vlos = df['radial_velocity'].values * u.km / u.s\n",
    "\n",
    "# Create a SkyCoord object for all sources at once\n",
    "coords = ICRS(ra=ra, dec=dec, distance=distance, pm_ra_cosdec=pmra, pm_dec=pmdec, radial_velocity=vlos)\n",
    "\n",
    "# Transform all coordinates to the Galactocentric frame\n",
    "cg = coords.transform_to(gc_frame)\n",
    "cg.representation= 'cylindrical'\n",
    "\n",
    "# Ensure cylindrical position and velocity representations\n",
    "cg_cyl = cg.represent_as(CylindricalRepresentation)  # Cylindrical position (rho, phi, z)\n",
    "cg_cyl_vel = cg.represent_as(CylindricalRepresentation, CylindricalDifferential).differentials['s']  # Cylindrical velocity\n",
    "\n",
    "# Convert d_phi from rad/yr to rad/s\n",
    "d_phi_rad_s = cg_cyl_vel.d_phi.to(u.rad / u.s)\n",
    "\n",
    "# Convert rho from pc to km\n",
    "rho_km = cg_cyl.rho.to(u.km)\n",
    "\n",
    "# Compute v_phi (linear azimuthal velocity in km/s)\n",
    "v_phi_kms = -(d_phi_rad_s * rho_km)\n",
    "\n",
    "df['v_phi'] = v_phi_kms.value\n",
    "\n",
    "# Convert d_rho to km/s\n",
    "v_r_kms = cg_cyl_vel.d_rho.to(u.km / u.s)\n",
    "\n",
    "# Convert d_rho to km/s\n",
    "df['v_R'] = cg_cyl_vel.d_rho.to(u.km / u.s).value\n",
    "\n",
    "df['v_Z'] = cg_cyl_vel.d_z.to(u.km / u.s).value\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea8e7daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Saved file\n"
     ]
    }
   ],
   "source": [
    "# Save as FITS\n",
    "table_out = Table.from_pandas(df)\n",
    "table_out.write('../data/vis_main.fits', format='fits', overwrite=True)\n",
    "print(f\"[✓] Saved file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "018577cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of common source_id values: 2983932\n"
     ]
    }
   ],
   "source": [
    "from astropy.io import fits\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the datasets\n",
    "vis_main = fits.open('../data/vis_main.fits')[1].data\n",
    "df_v_final = fits.open('../data/df_v_final.fits')[1].data\n",
    "\n",
    "\n",
    "# Convert to DataFrames\n",
    "df_vis_main = pd.DataFrame(np.array(vis_main))\n",
    "df_v_final = pd.DataFrame(np.array(df_v_final))\n",
    "\n",
    "# Convert source_id to integers if needed\n",
    "df_vis_main['source_id'] = df_vis_main['source_id'].astype(str).astype(np.int64)\n",
    "df_v_final['source_id'] = df_v_final['source_id'].astype(str).astype(np.int64)\n",
    "\n",
    "# Find common source_ids\n",
    "common_source_ids = np.intersect1d(df_vis_main['source_id'], df_v_final['source_id'])\n",
    "\n",
    "# Output the result\n",
    "print(f'Number of common source_id values: {len(common_source_ids)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "158d43eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10060164, 56)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vis_main.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "635e4033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3404929, 51)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_v_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75363fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
